<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Kailash Budhathoki &middot; 
    
  </title>

  
  <link rel="canonical" href="/about/">
  

  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel="stylesheet">

  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <script src="https://code.jquery.com/jquery-3.7.1.slim.min.js" integrity="sha256-kmHvs0B+OpCW5GVHUNjv9rOmY0IvSIRcf7zGUDTDQM8=" crossorigin="anonymous"></script>
  <script src="/public/js/sidenotes.js"></script>

  
</head>


  <body class="theme-base-08">

    

    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <!-- <div class="masthead"> -->
        <!-- <div class="container"> -->
          <!-- <h3 class="masthead-title"> -->
            <!-- <a href="/" title="Home"></a>
            <small></small> -->
          <!-- </h3> -->
        <!-- </div> -->
      <!-- </div> -->

      <div class="container content">
        <div class="page">
  <h1 class="page-title">Kailash Budhathoki</h1>
  <h2 id="news">News</h2>
<p>ðŸš€ Weâ€™re hiring GPU Performance Engineers to accelerate AI inference at scale for Amazon Bedrock! If youâ€™re passionate about optimizing GPU workloads, building high-performance distributed inference solutions and unlocking the efficiency of state-of-the-art foundation models, we should talk. Send your CV to kaibud [at] amazon [dot] com.</p>

<h2 id="bio">Bio</h2>

<p>I am currently a Team Lead (Sr. Applied Scientist) in the AWS Deep Science for Systems and Services team, where I work at the intersection of machine learning and systems. Our teamâ€™s goal is to optimize foundation models for inference in <a href="https://aws.amazon.com/bedrock/">Amazon Bedrock</a>â€”driving higher hardware utilization, lower latency, and lower cost. We develop algorithms (e.g., for quantization, speculative decoding, structured sparsity, accelerating multi-LoRA inference) and optimize systems (e.g., inference engines like vLLM, kernel tuning, identifying inference perf bottlenecks) that power GenAI workloads in Amazon Bedrock without compromising model accuracy. Learn more about our teamâ€™s recent public works: <a class="citation" href="#park:2024:kdd-tutorial">(Park et al., 2024)</a><a class="citation" href="#kuebler:2025:proximal">(KÃ¼bler et al., 2025)</a>.</p>

<p>I joined <a href="https://www.amazon.science/latest-news/amazons-fourth-r-d-center-in-germany-is-dedicated-to-open-ai-research">Amazon Research Lablet TÃ¼bingen</a> (part of AWS AI) in 2020, where I developed algorithms / tools to help businesses explain complex cause-effect relationships underlying their business problems, and led cross-org effort within Amazon to launch them in production <a class="citation" href="#budhathoki:2022:rca-outliers-blog">(Budhathoki &amp; BlÃ¶baum, 2022)</a><a class="citation" href="#budhathoki:2021:rca-dist-change-blog">(Budhathoki, 2021)</a><a class="citation" href="#goetz:2022:gcm-announcement-aws">(GÃ¶tz &amp; Budhathoki, 2022)</a>.
<!-- Typical business problems involved effect estimation, and root cause analysis of changes / outliers. Some solutions are still actively used in production by -->
Businesses like Amazon Supply Chain and Amazon Ads actively use those solutions for effect estimation and root cause analysis of changes / outliers.
Those algorithmic solutions were also open-sourced to the Python <a href="https://github.com/py-why/dowhy">DoWhy</a> library under a new package called <a href="https://www.pywhy.org/dowhy/v0.9.1/user_guide/gcm_based_inference/introduction.html"><code class="language-plaintext highlighter-rouge">gcm</code></a> <a class="citation" href="#goetz:2022:gcm-announcement-aws">(GÃ¶tz &amp; Budhathoki, 2022)</a><a class="citation" href="#bloebaum:2023:aws-rca-blog">(BlÃ¶baum et al., 2023)</a><a class="citation" href="#kiciman:2022:gcm-announcement-msr">(Emre Kiciman, 2022)</a>. This collaboration with Microsoft Research led to a new GitHub organization, <a href="https://www.pywhy.org/">PyWhy</a>, with the mission to build an open source ecosystem for causal machine learning <a class="citation" href="#goetz:2022:gcm-announcement-aws">(GÃ¶tz &amp; Budhathoki, 2022)</a><a class="citation" href="#kiciman:2022:gcm-announcement-msr">(Emre Kiciman, 2022)</a>.
<!--  -->
Briefly, I also led the cross-org science effort within Amazon to deliver bias mitigation solutions for the first family of Amazonâ€™s in-house multimodal foundation models, called Titan Multimodal Embeddings model and Amazon Titan Image Generation model, towards their re:Invent 2023 release <a class="citation" href="#kleindessner:2025:fairness_on_the_fly">(Kleindessner et al., 2025)</a><a class="citation" href="#barth:2023:amzn-titan-vision-announcement">(Barth, 2023)</a><a class="citation" href="#ali:2023:fairness-eval">(Ali et al., 2023)</a>.</p>

<p>In 2020, I received the Doctoral Degree in Computer Science from the <a href="https://saarland-informatics-campus.de/">Saarland University</a>, where I conducted my doctoral research at the <a href="https://www.mpi-inf.mpg.de/home">Max Planck Institute for Informatics</a>. During my PhD, I also interned at the <a href="https://www.amazon.science/latest-news/amazons-fourth-r-d-center-in-germany-is-dedicated-to-open-ai-research">Amazon Research Lablet TÃ¼bingen</a> for 2.5 months in the spring of 2019. Earlier, in 2015, I completed my Masterâ€™s degree in Computer Science with honours from the <a href="https://saarland-informatics-campus.de/">Saarland University</a>. Prior to that I worked as a Software Developer at ImmuneSecurity A/S (now <a href="https://www.logpoint.com/en/">LogPoint</a>) between 2011 and 2013.
I studied Bachelorâ€™s Degree in Computer Engineering at the <a href="https://pcampus.edu.np/">Institute of Engineering, Pulchowk Campus</a> in Nepal (2006-2010).</p>

<h2 id="contact">Contact</h2>

<p>kailash [dot] buki [at] gmail [dot] com</p>

<h2 id="publications">Publications</h2>

<p>See my up-to-date publications on <a href="https://scholar.google.com/citations?hl=en&amp;user=O5yaQbgAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Google Scholar</a>.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="park:2024:kdd-tutorial">Park, Y., Budhathoki, K., Chen, L., KÃ¼bler, J., Huang, J., Kleindessner, M., Huan, J., Cevher, V., Wang, Y., &amp; Karypis, G. (2024). <i>Inference Optimization of Foundation Models on AI Accelerators</i>. https://arxiv.org/abs/2407.09111</span></li>
<li><span id="kuebler:2025:proximal">KÃ¼bler, J. M., Wang, Y.-X., Sabach, S., Ansari, N., Kleindessner, M., Budhathoki, K., Cevher, V., &amp; Karypis, G. (2025). A Proximal Operator for Inducing 2: 4-Sparsity. <i>Transactions on Machine Learning Research</i>.</span></li>
<li><span id="budhathoki:2022:rca-outliers-blog">Budhathoki, K., &amp; BlÃ¶baum, P. (2022). <i>New method identifies the root causes of statistical outliers</i>. https://www.amazon.science/blog/new-method-identifies-the-root-causes-of-statistical-outliers</span></li>
<li><span id="budhathoki:2021:rca-dist-change-blog">Budhathoki, K. (2021). <i>Explaining changes in real-world data</i>. https://www.amazon.science/blog/explaining-changes-in-real-world-data</span></li>
<li><span id="goetz:2022:gcm-announcement-aws">GÃ¶tz, P., &amp; Budhathoki, K. (2022). <i>AWS contributes novel causal machine learning algorithms to DoWhy Python library</i>. https://www.amazon.science/blog/aws-contributes-novel-causal-machine-learning-algorithms-to-dowhy</span></li>
<li><span id="bloebaum:2023:aws-rca-blog">BlÃ¶baum, P., Budhathoki, K., &amp; GÃ¶tz, P. (2023). <i>Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning</i>. https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/</span></li>
<li><span id="kiciman:2022:gcm-announcement-msr">Emre Kiciman, A. S. (2022). <i>DoWhy evolves to independent PyWhy model to help causal inference grow</i>. https://www.microsoft.com/en-us/research/blog/dowhy-evolves-to-independent-pywhy-model-to-help-causal-inference-grow/</span></li>
<li><span id="kleindessner:2025:fairness_on_the_fly">Kleindessner, M., Russell, C. M., Budhathoki, K., Turkmen, A. C., Deng, S., Gunjal, V., Swaminathan, A., Manmatha, R., &amp; Yang, H. (2025). <i>Mitigating Bias in Multimodal Models via Query Transformation</i>. Amazon Technologies Inc. https://patents.google.com/patent/US12229179B1/en</span></li>
<li><span id="barth:2023:amzn-titan-vision-announcement">Barth, A. (2023). <i>Amazon Titan Image Generator, Multimodal Embeddings, and Text models are now available in Amazon Bedrock</i>. https://aws.amazon.com/blogs/aws/amazon-titan-image-generator-multimodal-embeddings-and-text-models-are-now-available-in-amazon-bedrock</span></li>
<li><span id="ali:2023:fairness-eval">Ali, J., Kleindessner, M., Wenzel, F., Budhathoki, K., Cevher, V., &amp; Russell, C. (2023). Evaluating the Fairness of Discriminative Foundation Models in Computer Vision. <i>Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society</i>, 809â€“833.</span></li></ol>

</div>

<div class="footer">
  <span class="disclaimer">Disclaimer: The opinions expressed here are my own and do not necessarily represent those of current or past employers.</span>
</div>
      </div>
    </div>

    <!-- <label for="sidebar-checkbox" class="sidebar-toggle"></label> -->

    <script src='/public/js/script.js'></script>
  </body>
</html>
